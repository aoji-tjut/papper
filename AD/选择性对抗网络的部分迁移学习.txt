摘要
对抗学习已成功地嵌入到深度网络中，以学习可迁移的功能，从而减少了源域和目标域之间的分布差异。现有的域对抗网络假定跨域完全共享的标签空间。在存在大数据的情况下，有很大的动机将分类和表示模型从现有的大域迁移到未知的小域。本文介绍了部分迁移学习，它放宽了共享标签空间的假设，使目标标签空间只是源标签空间的子空间。先前的方法通常将整个源域与目标域匹配，这对于部分传输问题易于产生负传输。我们提出了选择性对抗网络（SAN），它通过选择异常源类别来同时规避负向迁移，并通过最大程度地匹配共享中的数据分布来促进正向迁移 标签空间。实验表明，我们的模型超出了一些基准数据集上部分迁移学习任务的最新结果。 

1简介
深度网络极大地改善了各种机器学习问题和应用程序的技术水平。目前，只有在有大量标记数据可用时，这些令人印象深刻的性能提升才会出现。由于经常无法即时为各种应用程序域手动标记足够的培训数据，因此对于缺少标记数据的问题，通常会通过利用现成的标记来建立有效的算法以减少标记消耗的强烈动机来自不同但相关的源域的数据。然而，这种有前途的迁移学习范式遭受了跨不同领域的数据分布变化的困扰，这在使分类模型适应目标任务方面构成了主要障碍[22]。现有的迁移学习方法假定共享标签空间以及跨源域和目标域的不同特征分布。这些方法通过学习领域不变来桥接不同领域 特征表示而无需使用目标标签，并且从源域学习的分类器可以直接应用于目标域。最近的研究表明，深层网络可以通过解开域背后变异的解释因素来学习更多的可迁移特性，以进行迁移学习[4，29]。通过将迁移学习嵌入到深度特征学习的流水线中以提取领域不变的深度表示，可以实现最新进展[26、15、6、27、17]。在存在大数据的情况下，我们可以轻松访问大规模的标签数据集，例如ImageNet-1K。因此，自然的雄心是将表示模型和分类模型直接从大规模数据集传输到我们的目标数据集，例如Caltech-256，后者通常是小型的，在训练和测试时类别不明。从大数据角度来看，我们可以假设大型数据集足够大，可以包含小型数据集的所有类别。从而， 我们介绍了一个新颖的部分迁移学习问题，它假设目标标签空间是源标签空间的子空间。如图1所示，这个新问题比标准迁移学习更具普遍性和挑战性，因为离群的源类别（“沙发”）在区分目标类别（“足球”和“双筒望远镜”）时会导致负迁移。因此，将整个源域和目标域作为以前的方法进行匹配并不是解决此新问题的有效方法。本文提出了选择性对抗网络（SAN），它在很大程度上扩展了深度对抗适应的能力[6]，以解决从大领域到小领域的部分迁移学习。 SAN调整共享标签空间中源数据和目标数据的分布，更重要的是，从异常源类中选择源数据。与以前的方法相比，一个关键的改进是能够同时促进相关数据的正向传输和缓解 对不相关数据的负面传输，可以在端到端框架中进行训练。实验表明，我们的模型超过了在公共基准数据集上进行部分迁移学习的最新结果。 

2相关工作
迁移学习[22]跨不同领域或任务，以减轻机器学习[21、5、30、28]，计算机视觉[24、8、13]和自然语言处理[3]的手动标签负担。迁移学习的主要技术难题是正式减少不同领域之间的分布差异。深度网络可以学习抽象表示，这些抽象表示可以解开数据背后变异的不同解释因素[2]，并且可以显示出不同种群之间的不变因素，这些因素可以很好地从原始任务迁移到相似的新任务[29]。因此，已经探索了深层网络来进行迁移学习[7、20、13]，多模式和多任务学习[3、19]，其中相对于以前的浅层迁移学习方法，已经见证了显着的性能提升。但是，最新的进展表明，深度网络可以学习只能减少但不能消除跨域差异的抽象特征表示[7，26]，从而 目标任务的风险无限[18，1]。最近的一些工作桥接了深度学习和领域适应[26、15、6、27、17]，通过添加适应层来匹配分布的均值嵌入，从而将深度卷积网络（CNN）扩展到领域适应[26、15] 17]，或通过添加子网作为域识别符，同时了解深度特征以使域识别器训练范式中的识别符混淆[6，27]。尽管性能得到了显着改善，但是这些现有技术方法可能会受到以下假设的限制：源域和目标域共享相同的标签空间。在部分迁移学习中违反了该假设，该学习将表示模型和分类模型从现有的大域迁移到未知的小域。据我们所知，这是解决对抗网络中部分迁移学习的第一项工作。 

3部分迁移学习
在本文中，我们提出了部分迁移学习，这是一种新颖的迁移学习范例，其中目标域标签空间Ct是源域标签空间Cs的子空间，即Ct⊂Cs。由于我们通常需要将模型从大规模数据集（例如ImageNet）迁移到小规模数据集（例如CIFAR10），因此这种新范例在实践中得到了广泛的应用。与标准迁移学习类似，在部分迁移学习中，我们还提供了ns t nt i = 1的与| Cs |相关联的示例的源域Ds = {（xsi，yis）} ns。类和与| Ct |相关的nt个未标记示例的目标域Dt = {xi} i = 1类，但不同的是，我们有| Cs | > | Ct |在部分迁移学习中。源域和目标域分别从概率分布p和q采样。在标准迁移学习中，我们有p̸= q;在部分迁移学习中，我们还有pCt̸= q，其中pCt表示源域的分布 属于标签空间Ct的标签数据。本文的目的是设计一个深度神经网络，该网络能够学习迁移特征f = Gf（x）和自适应分类器y = Gy（f），以弥合跨域差异，从而使目标风险Pr（x， y）〜q [Gy（Gf（x））̸= y]通过利用源域监督来最小化。在标准迁移学习中，主要挑战之一是目标域没有标记数据，因此由于p̸= q的分布差异，在源域Ds上训练的源分类器Gy无法直接应用于目标域Dt。在部分迁移学习中，另一个更困难的挑战是我们甚至不知道源域标签空间Cs的哪一部分与目标域标签空间Ct共享，因为在训练期间Ct是不可访问的，这导致了两个技术难题。一方面，属于离群值标签空间Cs \ Ct的源域​​标签数据将对 整体传输性能。现有的深度迁移学习方法[15、6、27、17]通常假定源域和目标域具有相同的标签空间，并且匹配整个分布p和q，由于源标签空间和目标标签空间不同，因此容易产生负迁移因此原则上无法匹配。因此，如何消除或至少减小源标签数据在异常标签空间Cs \ Ct中的影响是减轻负向迁移的关键。另一方面，减小pCt和q之间的分布差异对于实现在共享标签空间Ct中的知识迁移至关重要。总而言之，实现部分迁移学习存在两个基本挑战。 （1）通过过滤掉属于异常标签空间Cs \ Ct的无关标签数据来规避负向传输。 （2）通过最大程度地匹配共享标签空间Ct中的数据分布pCt和q来促进正向传输。我们提出了一种新颖的选择性 对抗网络来应对这两个挑战。 

3.1域对抗网络
领域对抗网络已经通过提取可迁移的特征而成功地应用于迁移学习[6，27]，这些特征可以减少源域和目标域之间的分布偏移。 对抗学习过程是一个两人游戏，其中第一个玩家是经过训练的区分域Gd，用来区分源域和目标域，第二个玩家是同时经过微调以混淆区分域的特征提取器Gf。
为了提取域不变特征f，通过最大化域鉴别器Gd的损失来学习特征提取器Gf的参数θf，而通过最小化域鉴别器的损失来学习域鉴别器Gd的参数θd。 另外，标记预测因子Gy的损失也被最小化。 领域对抗网络[6]的目标是功能：

3.2选择性对抗网络
但是，在部分迁移学习中，目标域标签空间是源域标签空间Ct⊂Cs的子集。因此，匹配整个源域分布p和目标域分布q将导致由异常标记空间Cs \ Ct引起的负传递。与目标标签空间Ct相比，离群标签空间Cs \ Ct越大，负转印效果将越严重。为了应对负迁移，我们应该找到一种方法，在进行域对抗调整时，可以选择Cs \ Ct中的异常源类以及相关的源标记数据。
为了匹配不同标签空间Cs̸= Ct的源域​​和目标域，我们需要拆分域
将等式（1）中的歧视者Gd区分为| Cs |类域标识符Gkd，k = 1，...，| Cs |，
每个都负责匹配与标签k关联的源和目标域数据，如图所示
在图2中。由于在训练过程中无法访问目标标签空间Ct，而目标域
数据完全未加标签，因此很难确定Gkd负责哪个域区分符
每个目标数据点。幸运的是，我们观察到标签预测变量yˆ = G（x）输出到iyi
每个数据点xi是在源标签空间Cs上的概率分布。这个分布很好
表征为每个| Cs |分配xi的概率类。因此，使用自然
yˆ作为将每个数据点x分配给| C |的概率域标识符Gk，k = 1，。 。 。 ，| C |。 iisds
每个点xi对不同鉴别符的分配可以通过对所有| C |进行概率加权的域鉴别符丢失来实现。域标识符Gkd，k = 1，。 。 。 ，| Cs |如下所示，其中Gkd是第k个域标识符，而Lkd是其交叉熵损失，而di是域
点xi的标签。与公式（1）中的单区分域对抗网络相比，
拟议中的多区分域对抗网络可实现细粒度的适应，其中
每个数据点xi根据其概率仅与那些相关的域区分符匹配
ˆ。这种细粒度的适应可能会带来三个好处。 （1）避免了i的硬分配
每个域仅指向一个域识别符，这对于目标域数据而言往往不准确。 （2）它避免了负迁移，因为每个点仅与一个或几个最相关的类别对齐，而无关的类别则由概率加权域鉴别器损失滤除。 （3）概率加权域鉴别器的损失给不同的域鉴别器带来了不同的损失，自然而然地学习了多个具有不同参数θdk的域鉴别器。这些具有不同参数的域标识符可以促进每个实例的正传递。
除了上述实例级别的加权机制外，我们还引入了另一种类级别的加权方法，以进一步消除异常源类Cs \ Ct和关联的源数据的负面影响。我们观察到，仅负责目标类别Ct的域鉴别器可有效地促进正向迁移，而负责异常源类别Cs \ Ct的其他鉴别器仅会引入噪声并恶化源域和目标域之间的正迁移。共享标签空间Ct。因此，我们需要降低负责异常源类的域标识符的权重，这可以通过对这些域标识符的类级加权来实现。由于目标数据不太可能属于异常源类，因此它们的概率yik，k∈Cs \ Ct也足够小。因此，我们可以按如下方式降低负责异常源类的域鉴别器的权重。选择性对抗网络（SAN）成功实现了部分迁移学习，它通过过滤掉异常源类Cs \ Ct同时避免了负迁移。通过最大程度地匹配共享标签空间Ct中的数据分布pCt和q来促进正向传输

4实验
我们在三个基准数据集上进行实验，以评估我们的方法针对几种最新的深度迁移学习方法的有效性。 代码和数据集将在线提供。

4.1设置
评估是在三个公共数据集上进行的：Office-31，Caltech-Office和ImageNet-Caltech。
Office-31 [24]是计算机视觉域适应的标准基准，包括从三个不同的域收集的4,652张图像和31个类别：亚马逊（A），其中包含从amazon.com，网络摄像头（W）和DSLR下载的图像（D），分别包含使用不同设置的网络相机和数码SLR相机拍摄的图像。我们将具有31个类别的三个域分别表示为A 31，W 31和D31。然后我们使用Office-31和Caltech-256共享的十个类别，并在Office-31的每个域中选择这十个类别的图像作为目标域，分别表示为A 10，W 10和D10。我们评估六个迁移任务A 31→W 10，D 31→W10，W31→D10，A31→D10，D31→A10和W31→A10的所有方法。这些任务代表源域和目标域都具有少量类的环境下的性能。
通过使用Caltech-256（C 256）[11]作为源域，并使用Office 31中的三个域作为目标域来构建Caltech-Office [8]。我们使用Caltech-256和Office-31共享的十个类别，并在Office-31的每个域中选择这十个类别的图像作为目标域[8、16、25]。将源域表示为C 256，我们可以构建3个传输任务：C 256→W 10，C 256→A 10和C 256→D10。此设置旨在测试源域具有以下条件的任务设置上不同方法的性能比目标域多得多的类。ImageNet-Caltech使用ImageNet-1K [23]数据集（包含1000个类别）和Caltech-256（包含256个类别）构建。它们共有84个通用类，因此我们形成了两个传递学习任务：ImageNet 1000→Caltech 84和Caltech 256→ImageNet84。为防止预训练模型对ImageNet的影响，当使用ImageNet时，我们使用ImageNet验证集ImageNet用作源域时将其作为目标域和ImageNet训练集。此设置表示源域和目标域中具有大量类的任务的性能。
我们将SAN的性能与最先进的迁移学习和深度学习方法进行了比较：卷积神经网络（AlexNet [14]），深度适应网络（DAN）[15]，反向梯度（RevGrad）[6]和残差传输网络（RTN）[17]。 DAN通过将多个特定于任务的层的深层功能嵌入到内核Hilbert空间（RKHS）中，并使用多内核MMD最佳地匹配不同的分布，从而学习可迁移的功能。 RevGrad通过对抗性训练范例使区分域分类器的源域和目标域无法区分，从而改善了域适应性。 RTN通过深度残差学习共同学习可迁移的特征并适应不同的源分类器和目标分类器[12]。在目标标签空间是源标签空间的子空间的情况下，所有现有方法都无法解决部分迁移学习的问题。为了进一步了解选择性机制和使熵最小化的功效，我们通过评估SAN的两个变体来进行消融研究：（1）SAN选择性是没有选择性机制的变体； （2）SAN熵是没有使熵最小化的变体。
我们遵循标准协议，并使用所有标记的源数据和所有未标记的目标数据进行无监督的迁移学习[24，15]。我们使用三个随机实验比较每个迁移任务的平均分类准确性。对于基于MMD的方法（DAN和RTN），我们在训练数据上使用带宽b设置为中值成对平方距离的高斯核，即中值启发式[10]。对于所有方法，我们对带标签的源数据执行交叉评估以选择参数。
我们基于Caffe深度学习框架实施所有深度方法，并通过
由Caffe提供的AlexNet模型[14]在ImageNet上进行了预训练。我们在之间添加了一个瓶颈层
f c7和f c8层作为RevGrad [6]，除了任务ImageNet 1000→Caltech 84外，因为
预训练模型在ImageNet数据集上训练，它可以充分利用预训练的优势
具有原始fc7和fc8层的模型。对于SAN，我们微调所有要素层并进行训练
瓶颈层，分类器层和对抗网络。由于这些新层和
网络是从头开始训练的，我们将其学习率设置为其他层的10倍。
我们使用动量为0.9且学习率为的小批量随机梯度下降（SGD）
RevGrad [6]中实施的退火策略：未通过网格搜索选择学习率
由于计算成本高：在SGD期间使用以下公式进行调整：η=η0，p（1 +αp）β
其中p是训练进度，从0到1线性变化，η0= 0.001，α= 10和β= 0.75，这是针对源域中的低误差进行了优化的。由于SAN可以在不同的传输任务中稳定地工作，因此对抗网络的惩罚从RevGrad [6]逐渐从0增加到1。

4.2结果
表1和2显示了Office-31的六个任务，Caltech-Office的三个任务和ImageNet-Caltech的两个任务的分类结果。SAN模型在所有任务上均优于所有比较方法。尤其是，SAN通过在具有较小源域和较小目标域（例如， A 31→W 10，A 31→D 10以及具有较大源域和较小目标域的任务，例如C 31→W10。它在具有大规模源域和目标域（例如I 1000→C84。这些结果表明，在目标标签空间是源标签空间的子空间的设置下，SAN可以在所有任务中学习可迁移的功能，以进行部分迁移学习。
结果揭示了几个有趣的发现。 （1）以前的深度迁移学习方法，包括基于RevGrad等对抗网络的方法和基于DAN等基于MMD的方法，其效果均不如标准的AlexNet，这说明了负迁移效应的影响。这些方法尝试将知识从源域的所有类迁移到目标域，但是源域中有一些类在目标域中不存在，也就是异常源数据。愚弄对抗网络以匹配离群值源数据和目标数据的分布，将使分类器更有可能在这些离群值类别中对目标数据进行分类，这易于产生负迁移。因此，这些先前方法的性能甚至比标准AlexNet还要差。但是，SAN在很大程度上要优于它们，这表明SAN可以通过消除与目标域无关的异常源类来有效避免负向迁移。 （2）RTN比AlexNet表现更好，因为它执行熵最小化准则，可以在某种程度上避免离群数据的影响。但是，将RTN与仅具有熵最小损失的SAN选择性进行比较，我们发现SAN选择性在大多数任务中均胜过RTN，这表明RTN还具有负面的迁移效应，即使RTN的残留分支也无法了解源与源之间的巨大差异。目标域。 SAN在所有任务中均胜过RTN，这证明我们的选择性对抗机制可以共同促进从相关源域数据到目标域的正向传输，并避免从异常源域数据到目标域的负向传输。
通过比较表1和表2中的SAN变量结果，我们将更深入地了解SAN的不同模块。（1）SAN胜过SAN选择性，证明使用选择性对抗机制可以选择性地将知识从源数据迁移到目标数据。它可以通过相应的域标识符成功选择属于与目标类共享的类的源数据。 （2）SAN胜过SAN熵，尤其是在源域和目标域根据类的数量不同而具有非常大的分配差距的任务中。 I 1000→C 84.熵最小化可以有效地降低预测每个不相关类的点的可能性，尤其是在存在大量不相关类的情况下，这反过来又可以提高选择性对抗机制的性能。这解释了从SAN熵到SAN的改进。

4.3分析
不同数量目标类别的准确性：我们通过改变目标类别的数目来研究更广泛的部分迁移学习。 图3（a）显示，当目标类别的数量减少时，RevGrad的性能会迅速下降，这意味着当域间隙增大时，负迁移会变得更加严重。 当目标类别的数量从31减少到20时，SAN的性能会下降，这时会出现负面的传输问题，但传输问题本身仍然很困难。 当目标类别的数量从20个减少到10个时，SAN的性能会提高，从而使传输问题本身变得更加容易。 当目标类别的数量减少时，SAN胜过RevGrad的余地就会变大。 当目标类别数为31时，SAN在标准转换学习设置中也胜过RevGrad。
收敛性能：我们通过训练过程研究测试错误来检查SAN的收敛性。 如图3（b）所示，由于负迁移，DAN和RevGrad的测试误差正在增加。 RTN收敛速度非常快，这取决于熵的最小化，但是收敛到比SAN高的测试错误。 SAN可以快速稳定地收敛到最低的测试错误，这意味着可以对其进行有效且稳定的训练，以实现正向传输并同时缓解负向传输。
特征可视化：我们可视化图4（a）–4（d）中DAN，RevGrad，RTN和SAN在传输任务A 31→W 10上的瓶颈表示的t-SNE嵌入[4]（带有类信息）和图5（a）-5（d）（带有域信息）。我们在源域中随机选择五个与目标域不共享的类，并选择五个与目标域共享的类。我们可以进行直观的观察。 （1）图4（a）显示了瓶颈特征混合在一起，这意味着DAN无法很好地区分源数据和目标数据；图5（a）显示目标数据已与所有源类别（包括那些离群类别）对齐，这体现了负迁移问题。 （2）图4（b）–4（c）显示，RevGrad和RTN都能很好地区分源域，但是大多数目标数据的功能都非常接近源数据，即使是错误的源类也是如此；图5（b）–5（c）进一步表明，RevGrad和RTN都倾向于将目标数据绘制成接近所有源类，甚至是不存在于目标域中的源类。因此，由于负向传输，它们在目标数据上的性能会降低。 （3）图4（d）和5（d）证明，当目标数据接近正确的源类别时，SAN可以区分源类别和目标类别中的不同类别，而异常源类别则不能影响目标类别。这些有希望的结果证明了选择性对抗适应和熵最小化的功效。

5结论
本文提出了一种新颖的选择性对抗网络方法来进行部分迁移学习。 与以前的基于自适应标签空间假设匹配整个源域和目标域的对抗性适应方法不同，该方法通过选择异常源类别来同时规避负传递，并通过最大程度地匹配共享标签空间中的数据分布来促进正传递 。 我们的方法成功解决了部分迁移学习，其中源标签空间包含目标标签空间，这已通过大量实验证明。

















