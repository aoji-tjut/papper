摘要
对抗性学习已被嵌入到深度网络中，以学习可纠缠且可转移的表示形式以进行领域自适应。现有的对抗域适应方法可能无法有效地将分类问题中固有的多峰分布的不同域对齐。在本文中，我们提出了条件对抗域适应，这是一个有原则的框架，可根据分类器预测中传达的区分性信息来调节广告适应模型。条件域对抗网络（CDAN）设计有两种新颖的条件策略：捕获特征表示和分类器预测之间的交叉协方差以改善可分辨性的多线性条件；以及控制分类器预测的不确定性以确保可传递性的熵条件。有了理论上的保证和几行代码，该方法已经超过了五个数据集上的最新结果。 

1简介
深度网络极大地改善了各种机器学习问题和应用程序的最新水平。当在大规模数据集上进行训练时，深度网络会学习表示形式，这些表示形式通常可用于各种任务[36、11、54]。但是，深度网络在将学习到的知识推广到新的数据集或环境方面可能很弱。甚至从训练域的细微变化也可能导致深度网络对目标域做出虚假预测[54、36]。尽管在许多实际应用中，需要将深层网络从可提供足够训练数据的源域传输到仅可使用未标记数据的目标域，但这种迁移学习范式因跨数据分布的转移而受到阻碍域[39]。学习减少训练和测试分布之间的数据集偏移的模型称为领域适应[38]。浅层域中的先前域适应方法 通过学习不变的特征表示或使用标记的源数据和未标记的目标数据估计实例重要性来桥接源和目标[24、37、15]。深度域适应方法的最新进展是通过将适应模块嵌入深度架构中，利用深层网络来学习可转移表示，同时解开数据背后的变异解释因素和跨域匹配特征分布[12、13、29、52、31、30， 51]。对抗性领域适应[12、52、51]与生成对抗网络（GAN）相似，在两人游戏中将对抗性学习和领域适应整合在一起。通过最小化将源与目标域区分开的分类错误来学习域区分符，而深度分类模型则学习由域区分符无法区分的可传递表示。与这些功能级别的方法相比，生成像素级别的自适应 通过使用“图像到图像”转换技术将源数据转换为目标域的样式，模型可以在原始像素空间中执行分布对齐[56、28、22、43]。另一系列的作品使用不同的域标识符[23、8、50]分别对齐要素和类的分布。尽管它们对于从分类[12、51、28]到细分[43、50、22]的各种任务具有一般效力，这些对抗领域的适应方法可能仍然受到两个瓶颈的约束。首先，当数据分布体现出复杂的多峰结构时，对抗性适应方法可能无法捕获这种多峰结构，从而在没有模式失配的情况下进行区分性对齐。这种风险来自对抗性学习的均衡挑战，因为即使区分词完全混淆，我们也无法保证两个分布足够相似[3]。请注意，无法通过对齐要素分布来解决此风险 由于多峰结构只能通过特征和类之间的互协方差依赖性来充分捕获，因此通过单独的域区分符将类和类通过[23、8、50]进行分类，[47、44]。其次，在不确定的情况下以区分信息为条件区分条件是有风险的。在本文中，我们通过形式化条件对抗域适应框架来应对上述两个挑战。有条件的生成对抗网络（CGAN）[34，35]的最新进展表明，可以通过对判别信息进行条件化生成器和判别器来使真实图像和生成图像的分布相似。基于条件洞察力的启发，本文提出了条件域对抗网络（CDAN），以利用分类器预测中传达的区分性信息来帮助对抗性适应。 CDAN模型的关键是一种新颖的条件域鉴别器，其条件是 特定领域特征表示和分类器预测的互协方差。我们进一步根据分类器预测的不确定性来确定域区分符，并在易于传递的示例中对区分符进行优先排序。整个系统可以通过反向传播在线性时间内解决。基于域自适应理论[4]，我们为泛化误差范围提供了理论保证。实验表明，我们的模型超过了五个基准数据集上的最新结果。 

2相关工作
领域适应[38，39]通过匹配边际分布[4​​9，37，15]或条件分布[55，10]，跨不同分布的不同领域概括了学习者。它在计算机视觉[42，18，16，21]和自然语言处理[9，14]中找到了广泛的应用。除了上述浅层架构之外，最近的研究表明，深层网络学习了更多可转移的表示形式，这些表示形式使数据背后的变异解释因素得以解开[6]，并显示出不同群体所基于的不变因素[14、36]。由于深度表示只能减少而不是消除跨域分布差异[54]，因此最近对深度域自适应的研究进一步使用两种主要的分布匹配技术将自适应模块嵌入了深度网络中：矩匹配[29，31，30 ]和对抗训练[12，52，13，51]。在对抗性网络（GANs）的开创下[17] 学习已成功探索生成模型。 GAN在两人游戏中构成两个网络：一个生成器，用于捕获数据分布；鉴别器，用于区分生成的样本和真实数据。在最小极大范式中训练网络，以使生成器学会欺骗鉴别器，同时使鉴别器难以被欺骗。 GAN的几个难题已经解决，例如改进的训练[2，1]和模式崩溃[34，7，35]，但仍然存在其他问题，例如未能匹配两个分布[3]。在面向领域学习的对抗学习中，已经利用了无条件学习，而有条件学习则仍在探索中。共享条件GAN的某些精神[3]，另一系列的作品使用单独的域区分符来匹配特征和类。霍夫曼等。文献[23]通过学习特征来欺骗域识别符和特定于类别的适应，从而实现全局域对齐 通过最小化受约束的多实例丢失。特别地，用于特征表示的对抗模块不以具有类别信息的类别适应模块为条件。 Chen等。文献[8]在分类器层上进行了分类对齐；即，多个域识别符仅将源分类器的softmax概率作为输入，而不是以类信息为条件。蔡等。 [50]在要素和类层上强加了两个独立的域标识符。这些方法没有在统一的条件域区分符中探索功能和类之间的依赖关系，这对于捕获数据分布基础的多峰结构很重要。本文扩展了条件对抗机制，通过在功能上定义类别识别符，同时在类信息上进行条件限定，来实现可区分和可转移的领域自适应。设计了两种新颖的调节策略来捕获 在控制分类器预测的不确定性的同时，特征表示与类别预测之间的互协方差依赖性。这与分别对齐要素和类[23、8、50]不同。 

3
条件对抗域自适应
在无监督域自适应中，我们给定了标记为nt i = 1的ns的源域Ds = {（xsi，yis）} ns，未标记nt的目标域Dt = {xj} j = 1例子。源域和目标域分别从联合分布P（xs，ys）和Q（xt，yt）进行采样，然后假设违反了P̸=Q。本文的目的是设计一个深度网络G：x􏱎→y，该形式正式减少跨域数据分布的变化，从而使目标风险εt（G）= E（ xt，yt）〜Q [G（xt）̸= yt]可以由源风险εs（G）= E（xs，ys）〜P [G（xs）̸= ys]加上分布差异光盘来定界（ P，Q）由新型条件域鉴别器量化。对抗学习是启用生成对抗网络（GAN）的关键思想[17]，已经成功地探索以最小化跨域差异[13，51]。用f = F（x）表示特征表示，用g = G（x）表示分类器预测 领域对抗神经网络（DANN）[13]是一款两人游戏：第一个玩家是经过训练的区分域D，经过训练可以区分源域和目标域，第二个玩家是特征表示F领域鉴别器的误差函数很好地对应于特征分布P（f）和Q（f）之间的差异[12]，这是界定领域适应理论中目标风险的关键[ 4]。 3.1条件判别器我们在两个方向上进一步改进了现有的对抗域自适应方法[12，52，51]。首先，当特征和类的联合分布，即P（xs，ys）和Q（xt，yt）在整个域之间不相同时，仅适应特征表示f可能不够。由于进行了定量研究，[54]深度表示最终沿深度网络从一般过渡到特定，可转移性显着下降 在特定领域特征层f和分类器层g中。其次，当特征分布是多峰的时，由于多类分类的性质，这是一个真实的场景，对于对抗网络而言，仅适应特征表示可能会面临挑战。最近的工作[17、2、7、1]揭示了仅将不同分布基础的一小部分组件与对抗网络相匹配的失败风险很高。即使鉴别符完全混淆了，我们也无法从理论上保证两个不同的分布是相同的[3]。本文通过形式化条件对抗域适应框架来解决上述两个挑战。条件生成对抗网络（CGAN）的最新进展[34]发现，通过根据相关信息（例如，关联的标签和关联的方式）对生成器和鉴别器进行条件化，可以更好地匹配不同的分布。条件GAN [25，35]产生全局一致的 来自具有高度可变性和多峰分布的数据集的图像。受条件GAN的激励，我们观察到在对抗域自适应中，分类器预测g传达有区别的信息，可能揭示多峰结构，而在适应特征表示f时可以加以确定。通过调节，可以同时对特征表示f和分类器预测g中的域方差建模。

图1：用于域自适应的条件域对抗网络（CDAN）架构，
领域特定的特征表示f和分类器预测g体现了跨域
由条件域识别符D共同减少的差距。（a）多线性（M）条件，
适用于低维场景，其中D通过多个
线性图f⊗g; （b）适应多维度情况的随机多线性（RM）条件，
其中通过随机化多线性图√1（Rff）⊙（Rgg）对分类器预测进行了条件限制。 d
熵条件（虚线）导致CDAN E在易于传递的示例中对D进行优先级排序。

3.2多线性条件
多线性图被定义为多个随机向量的外积。无限维非线性特征图的多线性图已成功地应用于将联合分布或条件分布嵌入到再生内核希尔伯特空间中[47，44，45，30]。给定两个随机向量x和y，联合分布P（x，y）可以用互协方差Exy [φ（x）⊗φ（y）]建模，其中φ是由某些再生内核诱导的特征图。这样的内核嵌入使得能够操纵跨多个随机变量的乘法相互作用。除了多线性映射x y优于串联x y [47，46]的理论优势外，我们进一步直观地解释了它的优越性。假定C类中的线性映射φ（x）= x和一热标签向量y。可以证明，均值映射Exy [x y] = Ex [x]⊕Ey [y]独立计算x和y的均值。相反，均值映射Exy [x y] = Ex [x | y = 1]。 。 。 ⊕Ex [x | y = C]计算 每个C类条件分布P（x | y）。优于级联，多线性映射x y可以完全捕获复杂数据分布背后的多峰结构。  

3.3条件域对抗网络
我们对特定于领域的特征表示f和分类器预测g启用条件对抗域自适应。我们共同将（1）w.r.t.源分类器G和特征提取器F，最小化（2）w.r.t.域标识符D，并最大化（2）w.r.t.特征提取器F和源分类器G。这会产生条件域对抗网络（CDAN）的极小极大问题：
其中λ是源分类器和条件域区分符之间的超参数，请注意h =（f，g）是域特定特征表示f和分类器预测g的对抗变量的联合变量。根据经验，我们可以安全地将f设置为最后一个特征层表示，将g设置为分类器层预测。在象像素级自适应任务[25，22]中不能传递下层特征的情况下，我们可以将f更改为下层表示。熵条件条件域识别符（9）的极小极大问题对不同的示例都具有同等的重要性，而具有不确定性预测的难以传递的示例可能会使条件对抗适应程序恶化。为了实现安全转移，我们通过熵准则H（g）= − Cc = 1 gc log gc来量化分类器预测的不确定性，其中C是类的数目，gc是预测类c的示例的概率。我们 通过以熵感知权重w（H（g））= 1 e加权条件域鉴别符的每个训练-H（g）实例，对具有某些预测的那些易于转移的实例进行区分。 CDAN（CDAN E）的熵条件变体可改善传递性，其公式为...
领域鉴别器赋予熵最小化原理[19]并鼓励进行某些预测，从而使CDAN E能够对未标记的目标数据进一步执行半监督学习。

3.4泛化误差分析我们对CDAN方法进行分析，采用领域适应理论的类似形式[5，4]。我们首先考虑固定表示空间f = F（x）上的源域和目标域，以及假设空间H中的源分类器G族[13]。用εP（G）= E（f，y）〜P [G（f）̸= y]表示假设G∈H w.r.t的风险。分布P和εP（G1，G2）= E（f，y）〜P [G1（f）̸= G2（f）]假设G1，G2∈H之间存在分歧。令G ∗ = arg minGεP（G ）εQ（G）是明确体现适应性概念的理想假设。假设G的目标风险εQ（G）的概率界[4]由源风险εP（G）加上分布差异εQ（G）􏸌εP（G）[εP（G ∗）εQ（G ∗）给出）] |εP（G，G ∗）−εQ（G，G ∗）|。 （11）域自适应的目标是减小分布差异|εP（G，G ∗）-εQ（G，G ∗）|。根据定义，εP（G，G ∗）= E（f，y）〜P [G（f）̸= G ∗（f）] = E（f，g）〜PG [g̸= G ∗（f） ] =εPG（G ∗），类似地，εQ（G，G ∗） =εQG（G ∗）。注意，PG =（f，G（f））f〜P（f）和QG =（f，G（f））f〜Q（f）是联合分布P（f，y）的代理。 Q（f，y）分别为[10]。根据代理，|εP（G，G ∗）−εQ（G，G ∗）| = |εPG（G ∗）−εQG（G ∗）|。定义（损失）差异假设空间∆􏸎{δ= | g − G ∗（f）| ：联合变量（f，g）上的G ∗∈H}，其中δ：（f，g）􏱎→{0,1}输出G ∗∈H的损失。基于上述差异假设空间∆，我们将Δ距离定义为d∆（PG，QG）􏸎sup􏱂E[δ（f，g）̸= 0] − E [δ（f，g）̸= 0]􏱂δ∈∆􏱂（f，g ）〜PG（f，g）〜QG􏱂= supG ∗∈H􏱂􏱂E（f，g）〜PG [| g-G ∗（f）| ≠0]-E（f，g）〜QG [| g-G ∗（f）| ≠0]􏱂􏱂（12）􏱂􏱂E（f，g）〜PG [g̸= G ∗（f）]-E（f，g）〜QG [g̸= G ∗（f）]􏱂􏱂 = |εPG（G ∗）−εQG（G ∗）|。因此，域差异|εP（G，G ∗）-εQ（G，G ∗）|可以以∆距离为上限。由于差异假设空间∆是连续函数类，因此假设域鉴别器族HD足够丰富，可以包含∆，∆⊂HD。这样的假设并非不切实际，因为我们 可以自由选择HD，例如可以适合任何功能的多层感知器。根据这些假设，我们表明训练域鉴别符D与d∆（PG，QG）有关：d∆（PG，QG）􏸌supD∈H􏱂􏱂E（f，g）〜P [D（f，g） ̸= 0] -E（f，g）〜Q [D（f，g）̸= 0]􏱂􏱂DGG􏱂（13）􏸌supD∈HD􏱂E（f，g）〜PG [D（f， g）＝ 1] E（f，g）〜QG [D（f，g）＝ 0]􏱂。在CDAN中训练最佳判别器D的过程中实现了这一最高要求，给出了d∆（PG，QG）的上限。同时，我们学习了表示f以最小化d∆（PG，QG），以εP（G）更好地逼近εQ（G）来约束minimax范式中的目标风险。 

4个实验
我们使用许多最新的转移学习和深度学习方法来评估提出的条件域对抗网络。代码将在http://github.com/thuml/CDAN上提供。

4.1设置Office-31 [42]是用于视觉域适应的最广泛使用的数据集，它从三个不同的域收集了4,652张图像和31个类别：亚马逊（A），网络摄像头（W）和DSLR（D）。我们评估六个转移任务A→W，D→W，W→D，A→D，D→A和W→A的所有方法。ImageCLEF-DA1是通过选择三个公共部门共享的12个公共类而组织的数据集。数据集（域）：Caltech-256（C），ImageNet ILSVRC 2012（I）和Pascal VOC 2012（P）。我们置换所有三个域并构建六个传输任务：I→P，P→I，I→C，C→I，C→P，P→C。 Office-Home [53]是比Office-31更好的组织但更困难的数据集，它由办公室和家庭环境中65个对象类别的15,500张图像组成，形成了四个极为不同的领域：艺术图像（Ar），剪贴画（Cl ），产品图片（Pr）和真实图片（Rw）。数字我们调查了三个数字的数据集：MNIST，USPS和街景房门号码（SVHN）。我们采用CyCADA [22]的评估协议，进行了三项转换 任务：从USPS到MNIST（U→M），从MNIST到USPS（M→U），从SVHN到MNIST（S→M）。我们使用以下训练集训练模型：MNIST（60,000），USPS（7,291），标准SVHN训练（73,257）。在标准测试集上报告了评估：MNIST（10,000），USPS（2,007）（图像数量在括号中）。 
VisDA-20172是一个具有挑战性的从真实到真实的数据集，具有两个截然不同的域：合成，从不同角度和不同闪电条件的3D模型渲染；真实自然的图像。它在培训，验证和测试领域的12个课程中包含超过280K图像。我们将条件域对抗网络（CDAN）与最新的域自适应方法进行了比较：深度适应网络（DAN）[29]，残差传输网络（RTN）[31]，域对抗神经网络（DANN）[13]，对抗性区分域自适应（ADDA）[51]，联合自适应网络（JAN）[30]，无监督的图像到图像转换（UNIT）[28]，生成自适应（GTA）[43]，周期一致的对抗域适应（CyCADA）[22]。我们遵循无监督域自适应的标准协议[12，30]。我们使用所有标记的源示例和所有未标记的目标示例，并基于三个随机实验比较平均分类准确性。我们进行 重要性加权交叉验证（IWCV）[48]为所有方法选择超参数。由于CDAN在不同的参数下性能稳定，因此对于所有实验，我们都将λ= 1固定为1。对于基于MMD的方法（TCA，DAN，RTN和JAN），我们在训练数据上使用高斯内核，其带宽设置为成对的成对距离[29]。我们采用AlexNet [27]和ResNet-50 [20]作为基础网络，所有方法的区别仅在于它们的区别。我们在Caffe中实现了基于AlexNet的方法，在PyTorch中实现了基于ResNet的方法。我们从ImageNet预先训练的模型中进行调整[41]，除了从头开始训练模型的数字数据集。我们通过反向传播训练新的层和分类器层，其中从头开始训练分类器，其学习率是较低层的10倍。我们采用动量为0.9的小批量SGD，学习率退火策略为[13]：学习率通过ηp=η0（1αp）-β进行调整，其中p是训练进度从0变为 1，重要性加权交叉验证优化了η0= 0.01，α= 10，β= 0.75 [48]。我们对鉴别器采用渐进式训练策略，通过将λ乘以1-exp（-δp），δ= 10将λ从0增加到1。 

4.2结果表1中报告了基于AlexNet和ResNet的Office-31的结果，如果协议相同，则直接从原始论文中报告基线的结果。在大多数传输任务中，CDAN模型的性能明显优于所有比较方法，其中CDAN E是性能最高的变体，而CDAN的性能稍差一些。希望CDAN在例如硬传输任务上实质性地促进分类准确性。 A-W和A D，其中源域和目标域实质上不同[42]。请注意，CDAN E甚至胜过了生成像素级域自适应方法GTA，后者在架构和目标上都有非常复杂的设计。表2l中报告了ImageCLEF-DA数据集的结果。CDAN模型在大多数传输任务上均优于比较方法，但仍有较小的改进空间。这是合理的，因为ImageCLEF-DA中的三个域在每个类别中大小相等且平衡，并且在视觉上更 与Office-31相似，这使以前的数据集更易于域适应。 
表3列出了Office-Home的结果。CDAN模型在大多数传输任务上的性能大大优于比较方法，并且还有较大的改进空间。一种解释是，Office-Home中的四个域具有更多的类别，在视觉上彼此更不相同，并且在每个域中都很难，域内的分类准确率要低得多[53]。由于域对齐在先前的工作中是类别不可知的，因此在存在大量类别的情况下，对齐的域可能对类别不友好。理想的是，CDAN模型对此类困难的领域适应任务产生更大的推动作用，这通过在分类器预测中利用复杂的多峰结构突出了对抗领域适应的能力。如表4所示，在数字数据集和合成到真实数据集上也获得了出色的结果。请注意，生成像素级自适应方法UNIT，CyCADA和GTA是专门针对 针对数字量身定制，并针对实际的适应任务进行综合。这就解释了为什么以前的特征级适应方法JAN的性能相当差。据我们所知，CDAN E是唯一在所有五个数据集上都能很好地起作用的方法，并且仍然是一个简单的判别模型。 

4.3分析
消融研究：我们研究方程（6）中随机矩阵的采样策略。我们分别使用仅从高斯分布和均匀分布中抽样一次的随机矩阵来证明CDAN E（具有高斯采样）和CDAN E（具有高斯采样）。表5显示，在随机变体中，CDAN E（无随机采样）表现最佳，而CDAN E（无统一采样）表现最佳。表1-4显示了CDAN E优于CDAN，证明了熵条件可以优先考虑易于传递的示例并鼓励某些预测。
调节策略：除了多线性调节之外，我们还研究了将域标识符应用于f和g串联的DANN- [f，g]，将域标识符插入特征层f和分类器层g的DANN-f和DANN-g。图2（a）显示了基于ResNet-50的A→W和A→D的精度。串联策略并不成功，因为它无法捕获要素和类之间的互协方差，这对领域适应至关重要[10]。图2（b）显示熵权e-H（g）与预测正确性非常吻合：如果预测正确，则熵权≈1，而如果预测不正确（不确定），则远小于1。这揭示了熵调节保证示例可传递性的能力。
分布差异：A距离是分布差异的一种度量[4，33]，定义为distA = 2（1-2ε），其中ε是经过训练以区分源与目标的分类器的测试误差。图2（c）显示了具有ResNet，DANN和CDAN功能的任务A→W，W→D的distA。我们观察到CDAN特征上的distA小于ResNet和DANN特征上的distA，这意味着CDAN特征可以更有效地减小域间隙。由于域W和D相似，因此任务W→D的distA小于A→W的distA，这意味着更高的精度。
收敛：我们证明ResNet，DANN和CDAN的收敛性，任务A→W的测试错误如图2（d）所示。 CDAN的收敛速度比DANN快，而CDAN（M）的收敛速度比CDAN（RM）快。请注意，CDAN（M）构成高维多线性图，其成本比CDAN（RM）略高，而CDAN（RM）的成本与DANN相似。
可视化：我们通过图3（a）–3（d）中的t-SNE [32]可视化ResNet，DANN，CDAN-f和CDAN-fg对任务A→W（31类）的表示。源和目标与ResNet不一致，与DANN的一致性更好，但类别没有得到很好的区分。 CDAN-f对它们进行了更好的排列，并且类别被更好地区分，而CDAN-fg显然比CDAN-f更好。这显示了根据判别性预测调整对抗性适应的好处。

5结论
本文介绍了条件域对抗网络（CDAN），一种具有多峰分布的域自适应新方法。与以前的对抗性适应方法仅在整个域内匹配特征表示的方法容易发生匹配不足的情况不同，所提出的方法进一步对区分性信息进行对抗性域适应，以实现多峰分布的对齐。实验验证了该方法的有效性。