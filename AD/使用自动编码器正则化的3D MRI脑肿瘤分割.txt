抽象。 通过3D磁性自动分割脑肿瘤
共振图像（MRI）对于诊断，监测和
疾病的治疗计划。 手动划界做法要求
解剖学知识是昂贵的，费时的并且由于人为错误而可能是准确的。 在这里，我们描述了基于3D MRI的肿瘤子区域分割语义分割网络
编码器-解码器体系结构。 由于训练数据集的大小有限，
添加了变分自动编码器分支以重建输入图像
为了规范化共享解码器并在其层上施加其他约束，它本身。 目前的方法在BraTS中赢得了第一名
2018年挑战

1引言
脑肿瘤分为原发性和继发性肿瘤。主
脑肿瘤起源于脑细胞，而继发性肿瘤转移
从其他器官进入大脑。原发性脑肿瘤最常见的类型是神经胶质瘤，它是由脑胶质细胞引起的。胶质瘤可以是低级的
（LGG）和高级（HGG）亚型。高度神经胶质瘤是侵略性的
迅速增长的恶性脑肿瘤类型，通常需要手术治疗并
放疗并有较差的生存预后。磁共振成像
（MRI）是用于脑肿瘤分析，监测和手术的关键诊断工具
规划。通常，会获取几种免费的3D MRI模态-
如T1，T1和造影剂（T1c），T2和流体衰减反转覆盖（FLAIR）-强调不同的组织特性和肿瘤区域
传播。例如，造影剂（通常为ado）会在T1c MRI方式中强调过度活跃的肿瘤子区域。
3D脑肿瘤的自动分割可以节省医生的时间，
为进一步的肿瘤分析和监测提供准确的可再现解决方案。最近，基于深度学习的分割技术已经超过了传统的计算机视觉方法，可以进行密集的语义分割。卷积神经网络（CNN）能够从示例中学习并演示
2D自然图像[6]和3D中最新的分割精度
医学图像模态[19]。
多模态脑肿瘤分割挑战（BraTS）旨在通过提供3D MRI数据集和医生标注的地面真相肿瘤分割标签来评估脑肿瘤分割的最新方法[5,18,4 ，2,3]。今年，BraTS 2018训练数据集包括285个
病例（210 HGG和75 LGG），每个病例具有4种3D MRI模式（T1，T1c，T2
和FLAIR）牢固对齐，重新采样为1x1x1 mm的各向同性分辨率，
骷髅头输入图像大小为240x240x155。数据收集
来自19个机构的数据，使用了各种MRI扫描仪。注释包括3个肿瘤
子区域：肿瘤增强，肿瘤周围水肿，坏死和
非增强型肿瘤核心。注释被组合为3个嵌套子区域：整个肿瘤（WT），肿瘤核心（TC）和增强肿瘤（ET），
如图2所示。另外两个没有地面真相标签的数据集
提供了验证和测试。这些数据集需要参与者
将分段蒙版上载到组织者的服务器以进行评估。的
验证数据集（66个案例）允许多次提交，并且设计用于
中间评估。测试数据集（191个案例）仅允许一个
提交，并用于计算最终挑战排名。
在这项工作中，我们描述了针对体积的语义分割方法
来自多模态3D MRI的3D脑肿瘤分割技术赢得了BraTS
2018年挑战我们遵循CNN的编码器-解码器结构，使用不对称的大型编码器来提取深度图像特征，并且解码器部分
重建密集的分割蒙版。我们还添加了变分自动编码器
（VAE）分支到网络以结合分段一起重建输入图像，以便规范化共享编码器。在推断时间，只有
使用主要的分段编码-解码器部分。

2相关工作
去年，在BraTS 2017上，表现最好的作品包括Kamnitsas等人。 [13]
谁建议整合鲁棒分割（EMMA）的几种模型，以及
Wang等。 [21]谁建议使用级联方法将肿瘤亚区域分段
各向异性卷积。 EMMA利用了几个经过独立培训的体系结构的集成。特别是EMMA结合了DeepMedic [14]，
FCN [16]和U-net [20]模型并整合了它们的分段预测。
在训练期间，他们使用的批处理大小为8，并且裁剪了64x64x64 3D补丁。
EMMA的各种模型合集展示了出色的综合性能，赢得了BraTS 2017挑战赛。 Wang等。 [21]第二名
采取了不同的方法，即为每个肿瘤亚区域训练3个网络
级联，随后的每个网络取前一个网络的输出
（已裁剪）作为输入。每个网络的结构相似，由一个
大型编码器部分（具有扩展卷积）和基本解码器。他们也
将3x3x3卷积内核分解为片内（3x3x1）和片间
（1x1x3）内核以节省GPU内存和计算时间。
今年，BraTS 2018表现最好的提交（除了当前
工作）包括Isensee等。 [12]在第二名，McKinly等。 [17]和周
等。 [23]，谁分享了第三名。 Isensee等。 [12]证明了
通用的U-net体系结构，只需做一些小的修改就足以实现
竞争表现。作者使用的批处理大小为2，裁剪大小为128x128x128。此外，作者还使用了来自
他们自己的机构（这为增强肿瘤带来了一些改善
骰子）。 McKinly等。 [17]提出了一个分割CNN，其中有一个DenseNet [11]
具有扩张卷积的结构被嵌入到类似U-net的网络中。的
作者还介绍了一种新的损失函数，即二进制交叉熵的泛化，以解决标签的不确定性。最后，周等。 [23]提议
使用不同网络的集合：考虑多尺度上下文
信息，通过共享骨干级联地分割3个肿瘤亚区域
权重并添加注意块。
与相关作品相比，我们使用的最大作物尺寸为160x192x128
但将批处理大小设为1，以使网络适合GPU
内存限制。我们还直接在输出后输出所有3个嵌套的肿瘤子区域
乙状结肠（而不是使用多个网络或超过
类）。最后，我们添加了另一个分支来规范共享编码器，
仅在训练期间使用。我们没有使用任何其他培训数据，
仅提供所提供的训练集。

图1.网络架构的示意图。 输入是四通道
3D MRI裁剪，然后是带有32个滤镜的初始3x3x3 3D卷积。 每个绿色
block是具有GroupNorm规范化的类似ResNet的块。 输出
分段解码器具有三个通道（与输入的空间大小相同）
然后是乙状结肠，用于三个肿瘤亚区域（WT，TC，
ET）。 VAE分支将输入图像重构为自身，并且仅在
培训以规范化共享编码器。

3方法
我们的分割方法遵循基于编码器/解码器的CNN架构
使用非对称较大的编码器提取图像特征，并使用较小的编码器
解码器以重建分割掩码[6,7,9,20,19]。 我们向编码器端点添加了一个额外的分支，以重建原始图像，类似于自动编码器架构。 使用自动编码器分支的动机是添加
自培训以来，对编码器部分的附加指导和规范化
数据集的大小是有限的。 我们遵循变式自动编码器（VAE）方法
以便更好地对编码器端点的功能进行聚类/分组。 我们描述
在接下来的小节中构建网络的各个部分（另请参见图1）

3.1编码器部分
编码器部分使用ResNet [10]块，其中每个块由两个
归一化和ReLU进行卷积，然后跳过加法标识
连接。 对于规范化，我们使用组规范化（GN）[22]，
当批次大小较小（浴池大小）时，显示出优于BatchNorm性能
在我们的情况下为1）。 我们遵循一种通用的CNN方法，将图像尺寸逐渐减小2，同时将特征尺寸增加2。
缩小尺寸，我们使用跨步卷积。 所有卷积均为3x3x3，初始
等于32的过滤器数。编码器端点的大小为256x20x24x16，并且
在空间上比输入图像小8倍。 我们决定进一步反对
缩小尺寸以保留更多空间内容。

3.2解码器部分
解码器的结构类似于编码器的结构，但每个编码器只有一个块
每个空间级别。 每个解码器级别都从大型化开始：减少数量
的特征以2的倍数（使用1x1x1卷积）并将空间加倍
尺寸（使用3D双线性上采样），然后添加编码器
等效空间水平的输出。 解码器的末尾具有相同的
作为原始图像的空间大小，并且特征数量等于初始图像
输入要素大小，然后将1x1x1卷积为3个通道和一个S形
功能。

3.3 VAE部分
从编码器端点输出开始，我们首先将输入减小到一个低
256的维空间（128代表均值，128代表std）。
然后，从高斯分布中抽取具有给定均值的样本
和std，并按照相同的方式重建为输入图像尺寸
架构作为解码器，除了我们不使用层间跳过连接
从这里的编码器。 VAE零件结构如表1所示。

表1. VAE解码器分支结构，其中GN代表组归一化
（组大小为8），Conv-3x3x3卷积，Conv1-1x1x1卷积，AddId-
附加身份/跳过连接，UpLinear-3D线性空间上采样，密集
-全连接层

3.4损失
我们的损失函数包括3个项：
L = Ldice + 0.1 * LL2 + 0.1 * LKL
Ldice是软骰子损耗[19]，应用于ppred的解码器输出以匹配
分割蒙版ptrue：。。。其中求和是体素方式的，并且是避免零除的小常数。
由于分段解码器的输出具有3个通道（
每个肿瘤子区域），我们只需将三个骰子损失函数相加即可。
LL2是VAE分支输出Ipred上与输入图像匹配的L2损失
输入：。。。
LKL是标准的VAE惩罚条款[15,8]，两者之间的KL差异
估计正态分布N（µ，σ2
）和先验分布N（0，1），其中
具有封闭形式的表示形式：。。。其中N是图像体素的总数。 我们凭经验发现了一个超参数
的权重为0.1，以在骰子和VAE损失项之间提供良好的平衡
方程式1。

3.5优化
我们使用初始学习率为α0= 1ee 4并逐步递增的Adam优化器
根据以下内容减少它：
α=α0* 1 1 eNe 0.9
（5）
其中e是纪元计数器，Ne是纪元总数（在我们的
案件）。 我们使用1的批量大小，并以随机顺序绘制输入图像（确保
每个训练图像每个时期绘制一次）。

3.6正则化
我们对卷积核参数使用L2范数正则化
权重为1e e 5。
初始编码器卷积。 我们已经尝试了
辍学（包括在每次卷积之后放置辍学层），但没有
找到任何其他的准确性改进。

3.7数据预处理和扩充
我们将所有输入图像归一化为均值和单位std为零（仅基于非零体素）。 我们应用随机的（每个通道）强度偏移（（0.1..0.1
image std）和比例（0.9..1.1）在输入图像通道上。 我们还应用了随机
轴镜像翻转（所有3个轴）的概率为0.5。

4结果
我们在Tensorflow [1]中实现了我们的网络，并在NVIDIA Tesla上对其进行了培训
使用BraTS 2018训练数据集（285个案例）的V100 32GB GPU，没有任何额外的内部数据。在训练期间，我们使用大小为160x192x128的随机作物，
这样可确保大多数图像内容保留在作物区域内。我们将4种可用的3D MRI模态连接到4通道图像中作为输入。
网络的输出是3个嵌套的肿瘤子区域（乙状结肠之后）。
我们报告了BraTS 2018验证方法的结果（66例）
和测试集（191例）。这些数据集提供了未知的
胶质瘤等级和未知的分割。我们上传了细分结果
到BraTS 2018服务器以评估每个班级的骰子，敏感性，特异性
和Hausdorff距离。
除了评估单个模型之外，我们还应用了测试时间增加
（TTA）通过镜像翻转输入的3D图像轴，并平均输出
得到的8个翻转的分割概率图。最后，我们将
10套模型（从头开始训练），以进一步提高性能。
表2显示了我们在BraTS 2018验证数据集上的模型结果。
在首次提交简短论文时（2018年7月13日），我们的骰子准确性
表现排名第二（团队名称为NVDLMED1
），用于所有3个细分标签（ET，WT，TC）。 TTA仅略微提高了性能，
但是10个模型的组合导致了1％的改善，这是一致的
与使用合奏的文献结果。
对于测试数据集，仅允许一次提交。我们的结果是
如表3所示，在BraTS 2018挑战赛上获得第一名。

图2.典型的细分示例，其中包含真实标签和预测标签
T1c MRI轴向，矢状和冠状切片。 整个肿瘤（WT）类别包括所有
可见标签（绿色，黄色和红色标签的组合），肿瘤核心（TC）类为
红色和黄色的组合，增强的肿瘤核心（ET）类以黄色显示（a
多发性肿瘤部分）。 预测的分割结果与基本事实相符
好。

表2. BraTS 2018验证数据集结果。 提出的分割方法的均值Dice和Hausdorff度量。 EN-增强肿瘤核心，WT-完整
肿瘤，TC-肿瘤核心。

表3. BraTS 2018测试数据集结果。 平均骰子和Hausdorff测量
建议的细分方法。 EN-增强肿瘤核心，WT-整个肿瘤，
TC-肿瘤核心。

在单个GPU（NVIDIA Tesla）上的每个训练时期（285个案例）
V100 32GB）需要9分钟。 训练模型300个历时需要2天。 我们已经
还在NVIDIA DGX-1服务器（包括8个与NVLink互连的V100 GPU）上训练了模型； 这样可以在6小时内训练模型（7.8倍
加速）。 对于单个V100 GPU上的单个模型，推理时间为0.4秒。

5讨论与结论
在这项工作中，我们描述了脑肿瘤的语义分割网络
多模态3D MRI的图像分割技术赢得了BraTS 2018挑战赛。
在尝试网络体系结构时，我们尝试了几种替代方法。例如，我们尝试将批次大小设为8，以便能够
使用BatchNorm（并利用批次统计信息），但是由于GPU
内存限制了使用较小的图像裁切大小所需的此修改，并且
导致性能下降。我们还尝试了更多复杂的数据增强技术，包括随机直方图匹配，
仿射图像变换和随机图像过滤
任何其他改进。我们尝试了几种数据后处理技术，以使用CRF来微调分段预测[14]，但没有找到
这是有益的（它对某些图像有所帮助，但使其他图像分割结果更糟）。进一步增加网络深度并不能改善
性能，但增加了网络宽度（功能/过滤器的数量）
持续改善结果。使用NVIDIA Volta V100 32GB GPU
与V100 16GB版本相比，我们能够将功能数量翻倍。
最后，附加的VAE分支有助于规范化共享编码器（在
存在有限的数据），这不仅提高了性能，而且对
为任何随机初始化始终如一地获得良好的训练精度。我们的
BraTS 2018测试数据集结果分别为0.7664、0.8839和0.8154
分别用于增强肿瘤核心，整个肿瘤和肿瘤核心。





















