抽象。 本文提出了一种用于3D医学图像分割的神经架构搜索（NAS）框架，以从较大的设计空间自动优化神经架构。 我们的NAS框架在编码器和解码器中搜索每层的结构，包括神经连接性和操作类型。 由于高分辨率3D医学图像难以在较大的离散体系结构空间上进行优化，因此还提出了一种基于连续松弛的新颖随机采样算法，用于基于可伸缩梯度的优化。 在具有基准数据集的3D医学图像分割任务上，由拟议的NAS框架自动设计的体系结构优于人工设计的3D U-Net，而且这种优化的体系结构非常适合用于不同任务。

1引言
最近，深度神经网络已被广泛用于医学图像分割任务。 但是，总的来说，它们的性能取决于手动的试错过程来决定网络体系结构，培训的超参数以及过程的前/后过程。 由于限于手动调整，因此它们在性能改进以及快速转移到相关任务方面将受到限制。 当前，通用深度学习领域中的相同问题促进了自动化机器学习（AutoML）的快速发展。 然而，与最近关于使用高级AutoML算法（例如神经体系结构搜索（NAS）[5、9、12]和神经优化器搜索[10]）用于一般计算机视觉任务的研究相比，只有很少的方法使用简单的方法 已经针对医学成像任务提出了超参数优化[6，7]。
在本文中，我们提出了一个用于AutoML的NAS框架，用于设计神经网络，尤其是3D医学图像分割。 3D U-Net [1]已广泛用于分割高分辨率3D医学图像（请参见[4、8、11]），因为可以通过编码器和解码器之间的跳过连接有效地利用语义和空间信息。但是，已经使用各种卷积滤波器类型，池类型，跳过连接和非线性激活函数手动设计了3D U-Net中每个层的卷积块。代替使用人工块，我们采用NAS框架为3D U-Net中的每一层获取块的自动调整结构，称为细胞，其中所有细胞结构和相关的神经操作参数（ （例如内核权重）以端到端的方式同时学习。为此，定义了四种类型的单元，即编码器正常单元，归约单元，解码器正常单元和扩展单元，以组成编码器以及用于学习的U-Net架构的解码器（请参见图1）。这不同于以前的NAS方法，后者仅对纯编码器网络使用两种类型的单元（普通单元和简化单元）[5、9]。在NAS上使用足够大的搜索空间以针对目标任务生成改进的网络体系结构非常重要。但是，由于在处理高分辨率3D图像时会占用大量内存并需要较长的运行时间，因此很难在如此大的空间上进行优化。此外，必须在以下两个混合域上求解NAS的精确双层公式：（1）有关每个单元中神经连接和操作类型的离散变量，以及（2）连续操作参数。该约束限制了梯度搜索在体系结构搜索中的使用。为了解决这个问题，我们提出了一种对离散变量使用Gumbel-softmax [3]采样的新颖连续逼近方法。这样就可以在双层优化中使用随机梯度下降（SGD）。这种采样过程还可以减少在源于连续松弛的异常巨大的网络中考虑整个连接性和操作的计算负担。即，所提出的具有随机采样的可区别NAS在可解决的大搜索空间方面以降低的计算成本支持了很大的可扩展性。据我们所知，这是利用完整的NAS框架自动设计3D医学图像分割任务架构的第一项工作。在基准3D医学图像分割数据集上的实验结果表明，与人为设计的3D U-Net [1]相比，所提出的可扩展NAS获得的网络性能更好。此外还显示，可以转移从具有大量标记数据的任务中找到的体系结构，以构建具有各种医疗模式的网络，以用于具有不同标记模式的MRI和CT的各种医学模式，从而实现不同的分割任务，这些医疗模式具有少量标记数据并实现更好的泛化性能。

3实验
数据集和评估在三个3D分割任务上评估了拟议的可扩展NAS（SCNAS），（1）脑肿瘤（MRI，484个标记图像，3个类别），（2）心脏（MRI，20个标记图像，1个类别） ），以及（3）来自医学细分十项全能挑战赛（MSD，http：//medicaldecathlon.com）的肺部（CT，带有64个标记的图像，1类），其中每个任务的输入模式，大小和输入方式都不同前景类，因此适合评估SCNAS的可推广性和可移植性。由于MSD数据集中未提供用于测试图像的真实标签，因此对训练图像进行5倍交叉验证（CV），以平均骰子相似系数作为度量进行评估。在这里，[2]中的作者提供了此5折CV的拆分，我们使用了它。对于SCNAS，将验证拆分后的训练集再次分为比例为4：1的两组，分别用于优化操作参数和体系结构参数。
实现细节将SCNAS的性能与我们的基准3D U-ResNet [4，11]获得的性能进行比较，该3D U-ResNet利用残差块，多个分割图[4]和注意门[8]以及那些从3D nnU-Net [2]的角度来看，从挑战结果的角度来看，可以将其视为表现最佳的单一模型。在3D U-ResNet和SCNAS中，都进行了基于补丁的训练和推断，以便在训练过程中将每个图像以预先定义的分辨率随机裁剪到非零值区域，而在测试中，将预测结果通过将基于补丁的推理结果与50％的重叠相结合而获得。输入补丁的大小基本上设置为128×128×128，并针对每个任务进行了修改，并考虑了中间形状和内存限制，就像在[2]中用于3D nnU-Net的那样。由于即使是相同的任务也会为3D图像提供不同的体素间距，因此首先对输入图像进行重采样，以使其具有0.7mm×0.7mm×0.7mm的相等体素间距，然后将z归一化分别应用于每个输入通道。按照[2]，我们在训练和测试时也使用了与[2]中使用的相同类型和参数的数据增强技术。但是，与文献[2]不同，在此评估中并未采用网络级联，来自不同体系结构的预测集合以及去除小的连接组件来仅通过使用NAS在设计网络体系结构时检查其效果。 SCNAS中每个边上的操作集O包含以下八种操作：3×3×3卷积，深度可分离的扩展3×3×3卷积，速率为2、3和4，最大和平均值为3×3×3 3D池，标识（跳过连接）和零。在这里，我们使用LeakyReLU-Conv-InstanceNorm进行卷积运算。如图1所示，SCNAS中的整个网络由12个自动设计的单元组成，每个单元都有4个节点。此堆叠单元的数量与3D U-ResNet的向下采样和向上采样分别相乘三倍（即2倍）一致。这里，SCNAS还原单元中的所有操作都跨越了第二步，而扩展单元对单元的输入执行预上采样。与3D U-ResNet相似，SCNAS中的缩小和扩展单元分别将给定输入的输出通道数量加倍和减半。它指出，SCNAS首先使用干细胞的48个输出通道优化了所有单元架构，以便将1的批处理量适合单个GPU。然后，通过将具有发现的细胞拓扑的茎通道数量增加到68个，来构建更大的网络，并从头开始对其进行重新训练。在这里，有68个通道使SCNAS推断发现的网络的计算复杂度类似于基线3D U-ResNet，在第一个卷积单元中，它具有32个输出通道，就FLOP而言：419.59 GFLOP（3D U-ResNet ）与424.76 GFLOP（SCNAS）有关的脑肿瘤任务。

SCNAS接受了200个时期的培训，批次大小为4，在4个V100 GPU上花费了一天的时间。在此SCNAS培训中，使用了ADAM优化器，其中初始学习率/ beta参数对于训练操作参数Θ设置为0.025 /（0.1，0.001），对于训练体系结构参数α设置为0.003 /（0.5，0.999）。如果检测到训练损失达到20个周期的平稳期，则学习率将降低10倍。重新训练SCNAS模型以及训练3D U-ResNet模型时，初始学习率为0.0003，β参数为（0.9，0.999）用于ADAM优化程序，批处理大小为8，如果30 epoch内训练损失没有减少，则学习率降低5倍，并且如果迭代持续了30 ep，则终止迭代500个纪元或学习率小于10×7。 3D U-ResNet和SCNAS的损失函数都是Jaccard距离[4]。

结果表1显示，在总体性能方面，SCNAS产生了比（人为设计的）3D U-ResNet更好的体系结构。特别是，SCNAS的性能与3D nnU-Net [2]相当甚至更好。在这里，应该注意的是3D nnU-Net根据其5倍CV期间的验证损失执行模型选择，而我们的模型在训练期间未考虑任何验证结果。在分别只有20和64个标记图像的心脏和肺分割任务上，3D U-ResNet以及SCNAS可能会过度适合训练集。因此，我们将SCNAS发现的架构从具有484张标记图像的脑肿瘤任务的第一个CV折叠转移到了这些任务。为此，我们修改了干细胞架构以根据每个任务匹配输入通道的数量，并且在迁移架构中的操作参数从头开始对每个任务进行了重新训练。结果，与他们自己的NAS结果相比，从脑肿瘤任务转移来的体系结构具有更好的泛化性能。图2显示了SCNAS针对脑肿瘤任务优化的细胞结构。我们推测所选的膨胀卷积有助于反映更全局的上下文，以提高分割结果。示例输入图像和来自脑肿瘤任务的相应分割输出如图3所示，与3D U-ResNet相比，SCNAS显示了更好的分割结果。

4。结论
在这项工作中，提出了一个用于自动设计架构的完整NAS框架，并在3D医学图像分割任务的基准数据集上进行了演示。在提出的框架中，将NAS公式化为寻找构成编码器和解码器的四种类型的小区的最佳结构。我们介绍了一种新颖的随机采样算法，该算法在适用于处理高分辨率3D医学图像的可伸缩性方面取得了显着改善。实证评估表明，通过建议的NAS自动优化的网络性能优于手动设计的3D U-Net，并且学习到的体系结构已成功转移到不同的分割任务中。